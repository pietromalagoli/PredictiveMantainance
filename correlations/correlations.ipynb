{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "import dask.dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import aux as aux\n",
    "from dask.distributed import SSHCluster,Client\n",
    "import anomalies as an\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[43mClient\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m10.67.22.165:42429\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/mapdb/lib/python3.11/site-packages/distributed/client.py:1018\u001b[0m, in \u001b[0;36mClient.__init__\u001b[0;34m(self, address, loop, timeout, set_as_default, scheduler_file, security, asynchronous, name, heartbeat_interval, serializers, deserializers, extensions, direct_to_workers, connection_limit, **kwargs)\u001b[0m\n\u001b[1;32m   1015\u001b[0m preload_argv \u001b[38;5;241m=\u001b[39m dask\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistributed.client.preload-argv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreloads \u001b[38;5;241m=\u001b[39m preloading\u001b[38;5;241m.\u001b[39mprocess_preloads(\u001b[38;5;28mself\u001b[39m, preload, preload_argv)\n\u001b[0;32m-> 1018\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1019\u001b[0m Client\u001b[38;5;241m.\u001b[39m_instances\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrecreate_tasks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ReplayTaskClient\n",
      "File \u001b[0;32m~/anaconda3/envs/mapdb/lib/python3.11/site-packages/distributed/client.py:1220\u001b[0m, in \u001b[0;36mClient.start\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1218\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_started \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[1;32m   1219\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1220\u001b[0m     \u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/mapdb/lib/python3.11/site-packages/distributed/utils.py:431\u001b[0m, in \u001b[0;36msync\u001b[0;34m(loop, func, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m e\u001b[38;5;241m.\u001b[39mis_set():\n\u001b[0;32m--> 431\u001b[0m         \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\n",
      "File \u001b[0;32m~/anaconda3/envs/mapdb/lib/python3.11/site-packages/distributed/utils.py:420\u001b[0m, in \u001b[0;36msync.<locals>.wait\u001b[0;34m(timeout)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m    419\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 420\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m    422\u001b[0m         loop\u001b[38;5;241m.\u001b[39madd_callback(cancel)\n",
      "File \u001b[0;32m~/anaconda3/envs/mapdb/lib/python3.11/threading.py:622\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    620\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 622\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/anaconda3/envs/mapdb/lib/python3.11/threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 324\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "client = Client(\"10.67.22.165:42429\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=os.path.abspath('./data/data.csv')\n",
    "\n",
    "df = dd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "hardware_list = ['SW-065', 'SW-088', 'SW-106', 'SW-115']\n",
    "\n",
    "engine_list = ['S117', 'S118', 'S169', 'S170']\n",
    "# metrics = ['S41','S110','S100','S101','S102','S106','S107','S108','S122','S124','S126']\n",
    "metrics = ['S166']\n",
    "# metrics = ['S112', 'S113', 'S114', 'S115',] #esterne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-8' coro=<Client._gather.<locals>.wait() done, defined at /home/pietromalagoli/anaconda3/envs/mapdb/lib/python3.11/site-packages/distributed/client.py:2199> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pietromalagoli/anaconda3/envs/mapdb/lib/python3.11/site-packages/distributed/client.py\", line 2208, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m time, anom, val \u001b[38;5;241m=\u001b[39m \u001b[43man\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manomaly_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhardware_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maggfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m engine_norm \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMinute\u001b[39m\u001b[38;5;124m'\u001b[39m:time, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAnomaly\u001b[39m\u001b[38;5;124m'\u001b[39m:anom, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValue\u001b[39m\u001b[38;5;124m'\u001b[39m:val})\n",
      "File \u001b[0;32m~/MAPD-B/dask/project/correlations/anomalies.py:77\u001b[0m, in \u001b[0;36manomaly_column\u001b[0;34m(df, hwid, metric, aggfunc)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21manomaly_column\u001b[39m(df, hwid, metric, aggfunc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;66;03m#ottieni i periodi\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m     history\u001b[38;5;241m=\u001b[39m\u001b[43maux\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maggregate_up_down\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43mhwid\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;66;03m#definisci una funzione che serve dopo \u001b[39;00m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_within_intervals\u001b[39m(value, intervals):\n",
      "File \u001b[0;32m~/MAPD-B/dask/project/correlations/aux.py:15\u001b[0m, in \u001b[0;36maggregate_up_down\u001b[0;34m(df, hwid, metric)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maggregate_up_down\u001b[39m(df, hwid, metric):\n\u001b[1;32m     14\u001b[0m     selection\u001b[38;5;241m=\u001b[39mdf[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhwid\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mhwid]\n\u001b[0;32m---> 15\u001b[0m     selection\u001b[38;5;241m=\u001b[39m\u001b[43mselection\u001b[49m\u001b[43m[\u001b[49m\u001b[43mselection\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmetric\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m#we use compute here because we already filtered and we can manage this much data furthermore the \u001b[39;00m\n\u001b[1;32m     16\u001b[0m                                                                 \u001b[38;5;66;03m#diff operations cause problems when the dataframe is distributed because of the edges\u001b[39;00m\n\u001b[1;32m     17\u001b[0m                                                                 \u001b[38;5;66;03m#of the data itself where the diff is not trivially solved.\u001b[39;00m\n\u001b[1;32m     18\u001b[0m                                                                 \n\u001b[1;32m     19\u001b[0m                                                                 \u001b[38;5;66;03m#STATS FOR A CALL OF THIS FUNCTION ON ALL COMBINATIONS OF hw and ['S117','S118','S169','S170'] metric\u001b[39;00m\n\u001b[1;32m     20\u001b[0m                                                                 \u001b[38;5;66;03m#Version with compute call: 9m 26 s\u001b[39;00m\n\u001b[1;32m     21\u001b[0m                                                                 \u001b[38;5;66;03m#Version without compute call: 20m 38s\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     selection[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mswitch\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mselection[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdiff()\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28mabs\u001b[39m)\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m math\u001b[38;5;241m.\u001b[39misnan(x) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/mapdb/lib/python3.11/site-packages/dask_expr/_collection.py:476\u001b[0m, in \u001b[0;36mFrameBase.compute\u001b[0;34m(self, fuse, **kwargs)\u001b[0m\n\u001b[1;32m    474\u001b[0m     out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mrepartition(npartitions\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    475\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39moptimize(fuse\u001b[38;5;241m=\u001b[39mfuse)\n\u001b[0;32m--> 476\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDaskMethodsMixin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/mapdb/lib/python3.11/site-packages/dask/base.py:376\u001b[0m, in \u001b[0;36mDaskMethodsMixin.compute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    353\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[1;32m    354\u001b[0m \n\u001b[1;32m    355\u001b[0m \u001b[38;5;124;03m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;124;03m    dask.compute\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 376\u001b[0m     (result,) \u001b[38;5;241m=\u001b[39m \u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/mapdb/lib/python3.11/site-packages/dask/base.py:662\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    659\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[1;32m    661\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m shorten_traceback():\n\u001b[0;32m--> 662\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[0;32m~/anaconda3/envs/mapdb/lib/python3.11/threading.py:622\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    620\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 622\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/anaconda3/envs/mapdb/lib/python3.11/threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 324\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "time, anom, val = an.anomaly_column(df, hardware_list[0], engine_list[2], aggfunc='max')\n",
    "engine_norm = pd.DataFrame({'Minute':time, 'Anomaly':anom, 'Value':val})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating for metric S166\n"
     ]
    }
   ],
   "source": [
    "metric_list=[]\n",
    "\n",
    "for metric in metrics:\n",
    "    print(f\"Calculating for metric {metric}\")\n",
    "    values, minutes = aux.get_norm_data(df, hardware_list[0], metric)\n",
    "    metric_val = aux.fill_missing_min(values, minutes)\n",
    "    metric_norm = pd.DataFrame({'Minute':time, 'Value':metric_val})\n",
    "    metric_list.append(metric_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_finder(engine, metric_list, window):\n",
    "    \n",
    "    corr_coeff_pearson = []\n",
    "    corr_coeff_spearman = []\n",
    "    corr_coeff_kendall = []\n",
    "    tot_corr_coeff = []\n",
    "\n",
    "    for k in range(len(metric_list)):\n",
    "        corr_coeff_pearson.append([])\n",
    "        corr_coeff_spearman.append([])\n",
    "        corr_coeff_kendall.append([])\n",
    "\n",
    "    for metric in metric_list:\n",
    "        dftot = pd.DataFrame({'values_engine': list(engine.iloc[:,1]), 'values_metric': list(metric.iloc[:,1])})\n",
    "        corrs = [dftot.corr(method='pearson').iloc[0,1],dftot.corr(method='spearman').iloc[0,1],dftot.corr(method='kendall').iloc[0,1]]\n",
    "        tot_corr_coeff.append(corrs)\n",
    "\n",
    "    for i in range(len(engine['Anomaly'])):\n",
    "        if engine.iloc[i,1]:\n",
    "            values_engine = list(engine.iloc[i-window:i+window+1,2])\n",
    "            for j,metric in enumerate(metric_list):\n",
    "                values_metric = list(metric.iloc[i-window:i+window+1,1])\n",
    "\n",
    "                df = pd.DataFrame({'values_engine': values_engine, 'values_metric': values_metric})\n",
    "                corr_coeff_pearson[j].append(df.corr(method='pearson').iloc[0, 1])\n",
    "                corr_coeff_spearman[j].append(df.corr(method='spearman').iloc[0, 1])\n",
    "                corr_coeff_kendall[j].append(df.corr(method='kendall').iloc[0, 1])\n",
    "    return corr_coeff_pearson,corr_coeff_spearman,corr_coeff_kendall,tot_corr_coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scipy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pearson,spearman,kendall,tot\u001b[38;5;241m=\u001b[39m\u001b[43mcorr_finder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmetric_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43mwindow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 15\u001b[0m, in \u001b[0;36mcorr_finder\u001b[0;34m(engine, metric_list, window)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m metric_list:\n\u001b[1;32m     14\u001b[0m     dftot \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalues_engine\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlist\u001b[39m(engine\u001b[38;5;241m.\u001b[39miloc[:,\u001b[38;5;241m1\u001b[39m]), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalues_metric\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlist\u001b[39m(metric\u001b[38;5;241m.\u001b[39miloc[:,\u001b[38;5;241m1\u001b[39m])})\n\u001b[0;32m---> 15\u001b[0m     corrs \u001b[38;5;241m=\u001b[39m [dftot\u001b[38;5;241m.\u001b[39mcorr(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpearson\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m],dftot\u001b[38;5;241m.\u001b[39mcorr(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspearman\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m],\u001b[43mdftot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkendall\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m]]\n\u001b[1;32m     16\u001b[0m     tot_corr_coeff\u001b[38;5;241m.\u001b[39mappend(corrs)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(engine[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAnomaly\u001b[39m\u001b[38;5;124m'\u001b[39m])):\n",
      "File \u001b[0;32m~/anaconda3/envs/mapdb/lib/python3.11/site-packages/pandas/core/frame.py:11059\u001b[0m, in \u001b[0;36mDataFrame.corr\u001b[0;34m(self, method, min_periods, numeric_only)\u001b[0m\n\u001b[1;32m  11057\u001b[0m     min_periods \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m  11058\u001b[0m mat \u001b[38;5;241m=\u001b[39m mat\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m> 11059\u001b[0m corrf \u001b[38;5;241m=\u001b[39m \u001b[43mnanops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_corr_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m  11060\u001b[0m K \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(cols)\n\u001b[1;32m  11061\u001b[0m correl \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty((K, K), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/mapdb/lib/python3.11/site-packages/pandas/core/nanops.py:1622\u001b[0m, in \u001b[0;36mget_corr_func\u001b[0;34m(method)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_corr_func\u001b[39m(\n\u001b[1;32m   1619\u001b[0m     method: CorrelationMethod,\n\u001b[1;32m   1620\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Callable[[np\u001b[38;5;241m.\u001b[39mndarray, np\u001b[38;5;241m.\u001b[39mndarray], \u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m   1621\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkendall\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1622\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m kendalltau\n\u001b[1;32m   1624\u001b[0m         \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunc\u001b[39m(a, b):\n\u001b[1;32m   1625\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m kendalltau(a, b)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'scipy'"
     ]
    }
   ],
   "source": [
    "pearson,spearman,kendall,tot=corr_finder(engine_norm,metric_list,window=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{hardware_list[0]}_{engine_list[2]}_correlations.txt\",'a') as file:\n",
    "    for i,metric in enumerate(metrics):\n",
    "        file.write(f'Correlation coefficients for metric {metric}')\n",
    "        file.write('\\n\\n')\n",
    "        file.write(f'Pearson, Spearman and Kendall total correlations:')\n",
    "        file.write(' '.join(map(str,tot[i])))\n",
    "        file.write('\\n\\n')\n",
    "        file.write(f'Pearson coefficients: ')\n",
    "        file.write(' '.join(map(str,pearson[i])))\n",
    "        file.write('\\n')\n",
    "        file.write(f'Spearman coefficients: ')\n",
    "        file.write(' '.join(map(str,spearman[i])))\n",
    "        file.write('\\n')\n",
    "        file.write(f'Kendall coefficients: ')\n",
    "        file.write(' '.join(map(str,kendall[i])))\n",
    "        file.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#115-S118\n",
    "df = dd.read_csv(path)\n",
    "time, anom, val = an.anomaly_column(df, hardware_list[3], engine_list[1], aggfunc='max')\n",
    "engine_norm = pd.DataFrame({'Minute':time, 'Anomaly':anom, 'Value':val})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson,spearman,kendall,tot=corr_finder(engine_norm,metric_list,window=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{hardware_list[3]}_{engine_list[1]}_correlations.txt\",'a') as file:\n",
    "    for i,metric in enumerate(metrics):\n",
    "        file.write(f'Correlation coefficients for metric {metric}')\n",
    "        file.write('\\n\\n')\n",
    "        file.write(f'Pearson, Spearman and Kendall total correlations:')\n",
    "        file.write(' '.join(map(str,tot[i])))\n",
    "        file.write('\\n\\n')\n",
    "        file.write(f'Pearson coefficients: ')\n",
    "        file.write(' '.join(map(str,pearson[i])))\n",
    "        file.write('\\n')\n",
    "        file.write(f'Spearman coefficients: ')\n",
    "        file.write(' '.join(map(str,spearman[i])))\n",
    "        file.write('\\n')\n",
    "        file.write(f'Kendall coefficients: ')\n",
    "        file.write(' '.join(map(str,kendall[i])))\n",
    "        file.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#088-S169\n",
    "\n",
    "df = dd.read_csv(path)\n",
    "hardware_list = ['SW-065', 'SW-088', 'SW-106', 'SW-115']\n",
    "\n",
    "engine_list = ['S117', 'S118', 'S169', 'S170']\n",
    "# metrics = ['S41','S110','S100','S101','S102','S106','S107','S108','S122','S124','S126']\n",
    "metrics = ['S130','S171','S172','S173','S174','S179','S183','S204','S205','S206']   #binary circ2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time, anom, val = an.anomaly_column(df, hardware_list[1], engine_list[2], aggfunc='max')\n",
    "engine_norm = pd.DataFrame({'Minute':time, 'Anomaly':anom, 'Value':val})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating for metric S130\n",
      "Calculating for metric S171\n",
      "Calculating for metric S172\n",
      "Calculating for metric S173\n",
      "Calculating for metric S174\n",
      "Calculating for metric S179\n",
      "Calculating for metric S183\n",
      "Calculating for metric S204\n",
      "Calculating for metric S205\n",
      "Calculating for metric S206\n"
     ]
    }
   ],
   "source": [
    "metric_list=[]\n",
    "\n",
    "for metric in metrics:\n",
    "    print(f\"Calculating for metric {metric}\")\n",
    "    values, minutes = aux.get_norm_data(df, hardware_list[1], metric)\n",
    "    metric_val = aux.fill_missing_min(values, minutes)\n",
    "    metric_norm = pd.DataFrame({'Minute':time, 'Value':metric_val})\n",
    "    metric_list.append(metric_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson,spearman,kendall,tot=corr_finder(engine_norm,metric_list,window=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{hardware_list[1]}_{engine_list[2]}_correlations.txt\",'a') as file:\n",
    "    for i,metric in enumerate(metrics):\n",
    "        file.write(f'Correlation coefficients for metric {metric}')\n",
    "        file.write('\\n\\n')\n",
    "        file.write(f'Pearson, Spearman and Kendall total correlations:')\n",
    "        file.write(' '.join(map(str,tot[i])))\n",
    "        file.write('\\n\\n')\n",
    "        file.write(f'Pearson coefficients: ')\n",
    "        file.write(' '.join(map(str,pearson[i])))\n",
    "        file.write('\\n')\n",
    "        file.write(f'Spearman coefficients: ')\n",
    "        file.write(' '.join(map(str,spearman[i])))\n",
    "        file.write('\\n')\n",
    "        file.write(f'Kendall coefficients: ')\n",
    "        file.write(' '.join(map(str,kendall[i])))\n",
    "        file.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#088-S170\n",
    "df = dd.read_csv(path)\n",
    "time, anom, val = an.anomaly_column(df, hardware_list[1], engine_list[3], aggfunc='max')\n",
    "engine_norm = pd.DataFrame({'Minute':time, 'Anomaly':anom, 'Value':val})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson,spearman,kendall,tot=corr_finder(engine_norm,metric_list,window=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{hardware_list[1]}_{engine_list[3]}_correlations.txt\",'a') as file:\n",
    "    for i,metric in enumerate(metrics):\n",
    "        file.write(f'Correlation coefficients for metric {metric}')\n",
    "        file.write('\\n\\n')\n",
    "        file.write(f'Pearson, Spearman and Kendall total correlations:')\n",
    "        file.write(' '.join(map(str,tot[i])))\n",
    "        file.write('\\n\\n')\n",
    "        file.write(f'Pearson coefficients: ')\n",
    "        file.write(' '.join(map(str,pearson[i])))\n",
    "        file.write('\\n')\n",
    "        file.write(f'Spearman coefficients: ')\n",
    "        file.write(' '.join(map(str,spearman[i])))\n",
    "        file.write('\\n')\n",
    "        file.write(f'Kendall coefficients: ')\n",
    "        file.write(' '.join(map(str,kendall[i])))\n",
    "        file.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#106-S169\n",
    "df = dd.read_csv(path)\n",
    "hardware_list = ['SW-065', 'SW-088', 'SW-106', 'SW-115']\n",
    "\n",
    "engine_list = ['S117', 'S118', 'S169', 'S170']\n",
    "# metrics = ['S41','S110','S100','S101','S102','S106','S107','S108','S122','S124','S126']\n",
    "metrics = ['S130','S171','S172','S173','S174','S179','S183','S204','S205','S206'] #binary circ2\n",
    "# metrics = ['S112', 'S113', 'S114', 'S115',] #esterne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time, anom, val = an.anomaly_column(df, hardware_list[2], engine_list[2], aggfunc='max')\n",
    "engine_norm = pd.DataFrame({'Minute':time, 'Anomaly':anom, 'Value':val})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating for metric S130\n",
      "Calculating for metric S171\n",
      "Calculating for metric S172\n",
      "Calculating for metric S173\n",
      "Calculating for metric S174\n",
      "Calculating for metric S179\n",
      "Calculating for metric S183\n",
      "Calculating for metric S204\n",
      "Calculating for metric S205\n",
      "Calculating for metric S206\n"
     ]
    }
   ],
   "source": [
    "metric_list=[]\n",
    "\n",
    "for metric in metrics:\n",
    "    print(f\"Calculating for metric {metric}\")\n",
    "    values, minutes = aux.get_norm_data(df, hardware_list[2], metric)\n",
    "    metric_val = aux.fill_missing_min(values, minutes)\n",
    "    metric_norm = pd.DataFrame({'Minute':time, 'Value':metric_val})\n",
    "    metric_list.append(metric_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson,spearman,kendall,tot=corr_finder(engine_norm,metric_list,window=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{hardware_list[2]}_{engine_list[2]}_correlations.txt\",'a') as file:\n",
    "    for i,metric in enumerate(metrics):\n",
    "        file.write(f'Correlation coefficients for metric {metric}')\n",
    "        file.write('\\n\\n')\n",
    "        file.write(f'Pearson, Spearman and Kendall total correlations:')\n",
    "        file.write(' '.join(map(str,tot[i])))\n",
    "        file.write('\\n\\n')\n",
    "        file.write(f'Pearson coefficients: ')\n",
    "        file.write(' '.join(map(str,pearson[i])))\n",
    "        file.write('\\n')\n",
    "        file.write(f'Spearman coefficients: ')\n",
    "        file.write(' '.join(map(str,spearman[i])))\n",
    "        file.write('\\n')\n",
    "        file.write(f'Kendall coefficients: ')\n",
    "        file.write(' '.join(map(str,kendall[i])))\n",
    "        file.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#106-s170\n",
    "df = dd.read_csv(path)\n",
    "time, anom, val = an.anomaly_column(df, hardware_list[2], engine_list[3], aggfunc='max')\n",
    "engine_norm = pd.DataFrame({'Minute':time, 'Anomaly':anom, 'Value':val})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson,spearman,kendall,tot=corr_finder(engine_norm,metric_list,window=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{hardware_list[2]}_{engine_list[3]}_correlations.txt\",'a') as file:\n",
    "    for i,metric in enumerate(metrics):\n",
    "        file.write(f'Correlation coefficients for metric {metric}')\n",
    "        file.write('\\n\\n')\n",
    "        file.write(f'Pearson, Spearman and Kendall total correlations:')\n",
    "        file.write(' '.join(map(str,tot[i])))\n",
    "        file.write('\\n\\n')\n",
    "        file.write(f'Pearson coefficients: ')\n",
    "        file.write(' '.join(map(str,pearson[i])))\n",
    "        file.write('\\n')\n",
    "        file.write(f'Spearman coefficients: ')\n",
    "        file.write(' '.join(map(str,spearman[i])))\n",
    "        file.write('\\n')\n",
    "        file.write(f'Kendall coefficients: ')\n",
    "        file.write(' '.join(map(str,kendall[i])))\n",
    "        file.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#115-S169\n",
    "df = dd.read_csv(path)\n",
    "hardware_list = ['SW-065', 'SW-088', 'SW-106', 'SW-115']\n",
    "\n",
    "engine_list = ['S117', 'S118', 'S169', 'S170']\n",
    "# metrics = ['S41','S110','S100','S101','S102','S106','S107','S108','S122','S124','S126']\n",
    "metrics = ['S130','S171','S172','S173','S174','S179','S183','S204','S205','S206'] #binary circ2\n",
    "# metrics = ['S112', 'S113', 'S114', 'S115',] #esterne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time, anom, val = an.anomaly_column(df, hardware_list[3], engine_list[2], aggfunc='max')\n",
    "engine_norm = pd.DataFrame({'Minute':time, 'Anomaly':anom, 'Value':val})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating for metric S130\n",
      "Calculating for metric S171\n",
      "Calculating for metric S172\n",
      "Calculating for metric S173\n",
      "Calculating for metric S174\n",
      "Calculating for metric S179\n",
      "Calculating for metric S183\n",
      "Calculating for metric S204\n",
      "Calculating for metric S205\n",
      "Calculating for metric S206\n"
     ]
    }
   ],
   "source": [
    "metric_list=[]\n",
    "\n",
    "for metric in metrics:\n",
    "    print(f\"Calculating for metric {metric}\")\n",
    "    values, minutes = aux.get_norm_data(df, hardware_list[3], metric)\n",
    "    metric_val = aux.fill_missing_min(values, minutes)\n",
    "    metric_norm = pd.DataFrame({'Minute':time, 'Value':metric_val})\n",
    "    metric_list.append(metric_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson,spearman,kendall,tot=corr_finder(engine_norm,metric_list,window=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{hardware_list[3]}_{engine_list[2]}_correlations.txt\",'a') as file:\n",
    "    for i,metric in enumerate(metrics):\n",
    "        file.write(f'Correlation coefficients for metric {metric}')\n",
    "        file.write('\\n\\n')\n",
    "        file.write(f'Pearson, Spearman and Kendall total correlations:')\n",
    "        file.write(' '.join(map(str,tot[i])))\n",
    "        file.write('\\n\\n')\n",
    "        file.write(f'Pearson coefficients: ')\n",
    "        file.write(' '.join(map(str,pearson[i])))\n",
    "        file.write('\\n')\n",
    "        file.write(f'Spearman coefficients: ')\n",
    "        file.write(' '.join(map(str,spearman[i])))\n",
    "        file.write('\\n')\n",
    "        file.write(f'Kendall coefficients: ')\n",
    "        file.write(' '.join(map(str,kendall[i])))\n",
    "        file.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#115-S170\n",
    "df = dd.read_csv(path)\n",
    "time, anom, val = an.anomaly_column(df, hardware_list[3], engine_list[3], aggfunc='max')\n",
    "engine_norm = pd.DataFrame({'Minute':time, 'Anomaly':anom, 'Value':val})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson,spearman,kendall,tot=corr_finder(engine_norm,metric_list,window=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{hardware_list[3]}_{engine_list[3]}_correlations.txt\",'a') as file:\n",
    "    for i,metric in enumerate(metrics):\n",
    "        file.write(f'Correlation coefficients for metric {metric}')\n",
    "        file.write('\\n\\n')\n",
    "        file.write(f'Pearson, Spearman and Kendall total correlations:')\n",
    "        file.write(' '.join(map(str,tot[i])))\n",
    "        file.write('\\n\\n')\n",
    "        file.write(f'Pearson coefficients: ')\n",
    "        file.write(' '.join(map(str,pearson[i])))\n",
    "        file.write('\\n')\n",
    "        file.write(f'Spearman coefficients: ')\n",
    "        file.write(' '.join(map(str,spearman[i])))\n",
    "        file.write('\\n')\n",
    "        file.write(f'Kendall coefficients: ')\n",
    "        file.write(' '.join(map(str,kendall[i])))\n",
    "        file.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NON BINARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#088-169\n",
    "df = dd.read_csv(path)\n",
    "hardware_list = ['SW-065', 'SW-088', 'SW-106', 'SW-115']\n",
    "\n",
    "engine_list = ['S117', 'S118', 'S169', 'S170']\n",
    "# metrics = ['S41','S110','S100','S101','S102','S106','S107','S108','S122','S124','S126']\n",
    "metrics = ['S157', 'S158','S159','S163','S164','S165','S178','S180']\n",
    "# metrics = ['S112', 'S113', 'S114', 'S115',] #esterne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time, anom, val = an.anomaly_column(df, hardware_list[1], engine_list[2], aggfunc='max')\n",
    "engine_norm = pd.DataFrame({'Minute':time, 'Anomaly':anom, 'Value':val})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating for metric S157\n",
      "Calculating for metric S158\n",
      "Calculating for metric S159\n",
      "Calculating for metric S163\n",
      "Calculating for metric S164\n",
      "Calculating for metric S165\n",
      "Calculating for metric S178\n",
      "Calculating for metric S180\n"
     ]
    }
   ],
   "source": [
    "metric_list=[]\n",
    "\n",
    "for metric in metrics:\n",
    "    print(f\"Calculating for metric {metric}\")\n",
    "    values, minutes = aux.get_norm_data(df, hardware_list[1], metric)\n",
    "    metric_val = aux.fill_missing_min(values, minutes)\n",
    "    metric_norm = pd.DataFrame({'Minute':time, 'Value':metric_val})\n",
    "    metric_list.append(metric_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson,spearman,kendall,tot=corr_finder(engine_norm,metric_list,window=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{hardware_list[1]}_{engine_list[2]}_correlations.txt\",'a') as file:\n",
    "    for i,metric in enumerate(metrics):\n",
    "        file.write(f'Correlation coefficients for metric {metric}')\n",
    "        file.write('\\n\\n')\n",
    "        file.write(f'Pearson, Spearman and Kendall total correlations:')\n",
    "        file.write(' '.join(map(str,tot[i])))\n",
    "        file.write('\\n\\n')\n",
    "        file.write(f'Pearson coefficients: ')\n",
    "        file.write(' '.join(map(str,pearson[i])))\n",
    "        file.write('\\n')\n",
    "        file.write(f'Spearman coefficients: ')\n",
    "        file.write(' '.join(map(str,spearman[i])))\n",
    "        file.write('\\n')\n",
    "        file.write(f'Kendall coefficients: ')\n",
    "        file.write(' '.join(map(str,kendall[i])))\n",
    "        file.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#088-S170\n",
    "df = dd.read_csv(path)\n",
    "time, anom, val = an.anomaly_column(df, hardware_list[1], engine_list[3], aggfunc='max')\n",
    "engine_norm = pd.DataFrame({'Minute':time, 'Anomaly':anom, 'Value':val})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson,spearman,kendall,tot=corr_finder(engine_norm,metric_list,window=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{hardware_list[1]}_{engine_list[3]}_correlations.txt\",'a') as file:\n",
    "    for i,metric in enumerate(metrics):\n",
    "        file.write(f'Correlation coefficients for metric {metric}')\n",
    "        file.write('\\n\\n')\n",
    "        file.write(f'Pearson, Spearman and Kendall total correlations:')\n",
    "        file.write(' '.join(map(str,tot[i])))\n",
    "        file.write('\\n\\n')\n",
    "        file.write(f'Pearson coefficients: ')\n",
    "        file.write(' '.join(map(str,pearson[i])))\n",
    "        file.write('\\n')\n",
    "        file.write(f'Spearman coefficients: ')\n",
    "        file.write(' '.join(map(str,spearman[i])))\n",
    "        file.write('\\n')\n",
    "        file.write(f'Kendall coefficients: ')\n",
    "        file.write(' '.join(map(str,kendall[i])))\n",
    "        file.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#106-S169\n",
    "df = dd.read_csv(path)\n",
    "hardware_list = ['SW-065', 'SW-088', 'SW-106', 'SW-115']\n",
    "\n",
    "engine_list = ['S117', 'S118', 'S169', 'S170']\n",
    "# metrics = ['S41','S110','S100','S101','S102','S106','S107','S108','S122','S124','S126']\n",
    "metrics = ['S157', 'S158','S159','S163','S164','S165','S178','S180']\n",
    "# metrics = ['S112', 'S113', 'S114', 'S115',] #esterne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time, anom, val = an.anomaly_column(df, hardware_list[2], engine_list[2], aggfunc='max')\n",
    "engine_norm = pd.DataFrame({'Minute':time, 'Anomaly':anom, 'Value':val})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating for metric S157\n",
      "Calculating for metric S158\n",
      "Calculating for metric S159\n",
      "Calculating for metric S163\n",
      "Calculating for metric S164\n",
      "Calculating for metric S165\n",
      "Calculating for metric S178\n",
      "Calculating for metric S180\n"
     ]
    }
   ],
   "source": [
    "metric_list=[]\n",
    "\n",
    "for metric in metrics:\n",
    "    print(f\"Calculating for metric {metric}\")\n",
    "    values, minutes = aux.get_norm_data(df, hardware_list[2], metric)\n",
    "    metric_val = aux.fill_missing_min(values, minutes)\n",
    "    metric_norm = pd.DataFrame({'Minute':time, 'Value':metric_val})\n",
    "    metric_list.append(metric_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson,spearman,kendall,tot=corr_finder(engine_norm,metric_list,window=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{hardware_list[2]}_{engine_list[2]}_correlations.txt\",'a') as file:\n",
    "    for i,metric in enumerate(metrics):\n",
    "        file.write(f'Correlation coefficients for metric {metric}')\n",
    "        file.write('\\n\\n')\n",
    "        file.write(f'Pearson, Spearman and Kendall total correlations:')\n",
    "        file.write(' '.join(map(str,tot[i])))\n",
    "        file.write('\\n\\n')\n",
    "        file.write(f'Pearson coefficients: ')\n",
    "        file.write(' '.join(map(str,pearson[i])))\n",
    "        file.write('\\n')\n",
    "        file.write(f'Spearman coefficients: ')\n",
    "        file.write(' '.join(map(str,spearman[i])))\n",
    "        file.write('\\n')\n",
    "        file.write(f'Kendall coefficients: ')\n",
    "        file.write(' '.join(map(str,kendall[i])))\n",
    "        file.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#106-S170\n",
    "df = dd.read_csv(path)\n",
    "\n",
    "time, anom, val = an.anomaly_column(df, hardware_list[2], engine_list[3], aggfunc='max')\n",
    "engine_norm = pd.DataFrame({'Minute':time, 'Anomaly':anom, 'Value':val})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson,spearman,kendall,tot=corr_finder(engine_norm,metric_list,window=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{hardware_list[2]}_{engine_list[3]}_correlations.txt\",'a') as file:\n",
    "    for i,metric in enumerate(metrics):\n",
    "        file.write(f'Correlation coefficients for metric {metric}')\n",
    "        file.write('\\n\\n')\n",
    "        file.write(f'Pearson, Spearman and Kendall total correlations:')\n",
    "        file.write(' '.join(map(str,tot[i])))\n",
    "        file.write('\\n\\n')\n",
    "        file.write(f'Pearson coefficients: ')\n",
    "        file.write(' '.join(map(str,pearson[i])))\n",
    "        file.write('\\n')\n",
    "        file.write(f'Spearman coefficients: ')\n",
    "        file.write(' '.join(map(str,spearman[i])))\n",
    "        file.write('\\n')\n",
    "        file.write(f'Kendall coefficients: ')\n",
    "        file.write(' '.join(map(str,kendall[i])))\n",
    "        file.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#115-169\n",
    "df = dd.read_csv(path)\n",
    "hardware_list = ['SW-065', 'SW-088', 'SW-106', 'SW-115']\n",
    "\n",
    "engine_list = ['S117', 'S118', 'S169', 'S170']\n",
    "# metrics = ['S41','S110','S100','S101','S102','S106','S107','S108','S122','S124','S126']\n",
    "metrics = ['S157', 'S158','S159','S163','S164','S165','S178','S180']\n",
    "# metrics = ['S112', 'S113', 'S114', 'S115',] #esterne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time, anom, val = an.anomaly_column(df, hardware_list[3], engine_list[2], aggfunc='max')\n",
    "engine_norm = pd.DataFrame({'Minute':time, 'Anomaly':anom, 'Value':val})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating for metric S157\n",
      "Calculating for metric S158\n",
      "Calculating for metric S159\n",
      "Calculating for metric S163\n",
      "Calculating for metric S164\n",
      "Calculating for metric S165\n",
      "Calculating for metric S178\n",
      "Calculating for metric S180\n"
     ]
    }
   ],
   "source": [
    "metric_list=[]\n",
    "\n",
    "for metric in metrics:\n",
    "    print(f\"Calculating for metric {metric}\")\n",
    "    values, minutes = aux.get_norm_data(df, hardware_list[3], metric)\n",
    "    metric_val = aux.fill_missing_min(values, minutes)\n",
    "    metric_norm = pd.DataFrame({'Minute':time, 'Value':metric_val})\n",
    "    metric_list.append(metric_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson,spearman,kendall,tot=corr_finder(engine_norm,metric_list,window=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{hardware_list[3]}_{engine_list[2]}_correlations.txt\",'a') as file:\n",
    "    for i,metric in enumerate(metrics):\n",
    "        file.write(f'Correlation coefficients for metric {metric}')\n",
    "        file.write('\\n\\n')\n",
    "        file.write(f'Pearson, Spearman and Kendall total correlations:')\n",
    "        file.write(' '.join(map(str,tot[i])))\n",
    "        file.write('\\n\\n')\n",
    "        file.write(f'Pearson coefficients: ')\n",
    "        file.write(' '.join(map(str,pearson[i])))\n",
    "        file.write('\\n')\n",
    "        file.write(f'Spearman coefficients: ')\n",
    "        file.write(' '.join(map(str,spearman[i])))\n",
    "        file.write('\\n')\n",
    "        file.write(f'Kendall coefficients: ')\n",
    "        file.write(' '.join(map(str,kendall[i])))\n",
    "        file.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#115-S170\n",
    "df = dd.read_csv(path)\n",
    "time, anom, val = an.anomaly_column(df, hardware_list[3], engine_list[3], aggfunc='max')\n",
    "engine_norm = pd.DataFrame({'Minute':time, 'Anomaly':anom, 'Value':val})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson,spearman,kendall,tot=corr_finder(engine_norm,metric_list,window=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{hardware_list[3]}_{engine_list[3]}_correlations.txt\",'a') as file:\n",
    "    for i,metric in enumerate(metrics):\n",
    "        file.write(f'Correlation coefficients for metric {metric}')\n",
    "        file.write('\\n\\n')\n",
    "        file.write(f'Pearson, Spearman and Kendall total correlations:')\n",
    "        file.write(' '.join(map(str,tot[i])))\n",
    "        file.write('\\n\\n')\n",
    "        file.write(f'Pearson coefficients: ')\n",
    "        file.write(' '.join(map(str,pearson[i])))\n",
    "        file.write('\\n')\n",
    "        file.write(f'Spearman coefficients: ')\n",
    "        file.write(' '.join(map(str,spearman[i])))\n",
    "        file.write('\\n')\n",
    "        file.write(f'Kendall coefficients: ')\n",
    "        file.write(' '.join(map(str,kendall[i])))\n",
    "        file.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#065-169\n",
    "df = dd.read_csv(path)\n",
    "hardware_list = ['SW-065', 'SW-088', 'SW-106', 'SW-115']\n",
    "\n",
    "engine_list = ['S117', 'S118', 'S169', 'S170']\n",
    "# metrics = ['S41','S110','S100','S101','S102','S106','S107','S108','S122','S124','S126']\n",
    "metrics = ['S130','S171','S172','S173','S174','S179','S183','S204','S205','S206'] #binary circ2\n",
    "# metrics = ['S112', 'S113', 'S114', 'S115',] #esterne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time, anom, val = an.anomaly_column(df, hardware_list[0], engine_list[2], aggfunc='max')\n",
    "engine_norm = pd.DataFrame({'Minute':time, 'Anomaly':anom, 'Value':val})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating for metric S130\n",
      "Calculating for metric S171\n",
      "Calculating for metric S172\n",
      "Calculating for metric S173\n",
      "Calculating for metric S174\n",
      "Calculating for metric S179\n",
      "Calculating for metric S183\n",
      "Calculating for metric S204\n",
      "Calculating for metric S205\n",
      "Calculating for metric S206\n"
     ]
    }
   ],
   "source": [
    "metric_list=[]\n",
    "\n",
    "for metric in metrics:\n",
    "    print(f\"Calculating for metric {metric}\")\n",
    "    values, minutes = aux.get_norm_data(df, hardware_list[0], metric)\n",
    "    metric_val = aux.fill_missing_min(values, minutes)\n",
    "    metric_norm = pd.DataFrame({'Minute':time, 'Value':metric_val})\n",
    "    metric_list.append(metric_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson,spearman,kendall,tot=corr_finder(engine_norm,metric_list,window=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{hardware_list[0]}_{engine_list[2]}_correlations.txt\",'a') as file:\n",
    "    for i,metric in enumerate(metrics):\n",
    "        file.write(f'Correlation coefficients for metric {metric}')\n",
    "        file.write('\\n\\n')\n",
    "        file.write(f'Pearson, Spearman and Kendall total correlations:')\n",
    "        file.write(' '.join(map(str,tot[i])))\n",
    "        file.write('\\n\\n')\n",
    "        file.write(f'Pearson coefficients: ')\n",
    "        file.write(' '.join(map(str,pearson[i])))\n",
    "        file.write('\\n')\n",
    "        file.write(f'Spearman coefficients: ')\n",
    "        file.write(' '.join(map(str,spearman[i])))\n",
    "        file.write('\\n')\n",
    "        file.write(f'Kendall coefficients: ')\n",
    "        file.write(' '.join(map(str,kendall[i])))\n",
    "        file.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#065-169\n",
    "df = dd.read_csv(path)\n",
    "hardware_list = ['SW-065', 'SW-088', 'SW-106', 'SW-115']\n",
    "\n",
    "engine_list = ['S117', 'S118', 'S169', 'S170']\n",
    "# metrics = ['S41','S110','S100','S101','S102','S106','S107','S108','S122','S124','S126']\n",
    "metrics = ['S157', 'S158','S159','S163','S164','S165','S178','S180']\n",
    "# metrics = ['S112', 'S113', 'S114', 'S115',] #esterne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time, anom, val = an.anomaly_column(df, hardware_list[0], engine_list[2], aggfunc='max')\n",
    "engine_norm = pd.DataFrame({'Minute':time, 'Anomaly':anom, 'Value':val})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating for metric S157\n",
      "Calculating for metric S158\n",
      "Calculating for metric S159\n",
      "Calculating for metric S163\n",
      "Calculating for metric S164\n",
      "Calculating for metric S165\n",
      "Calculating for metric S178\n",
      "Calculating for metric S180\n"
     ]
    }
   ],
   "source": [
    "metric_list=[]\n",
    "\n",
    "for metric in metrics:\n",
    "    print(f\"Calculating for metric {metric}\")\n",
    "    values, minutes = aux.get_norm_data(df, hardware_list[0], metric)\n",
    "    metric_val = aux.fill_missing_min(values, minutes)\n",
    "    metric_norm = pd.DataFrame({'Minute':time, 'Value':metric_val})\n",
    "    metric_list.append(metric_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson,spearman,kendall,tot=corr_finder(engine_norm,metric_list,window=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "with open(f\"{hardware_list[0]}_{engine_list[2]}_correlations.txt\",'a') as file:\n",
    "    for i,metric in enumerate(metrics):\n",
    "        file.write(f'Correlation coefficients for metric {metric}')\n",
    "        file.write('\\n\\n')\n",
    "        file.write(f'Pearson, Spearman and Kendall total correlations:')\n",
    "        file.write(' '.join(map(str,tot[i])))\n",
    "        file.write('\\n\\n')\n",
    "        file.write(f'Pearson coefficients: ')\n",
    "        file.write(' '.join(map(str,pearson[i])))\n",
    "        file.write('\\n')\n",
    "        file.write(f'Spearman coefficients: ')\n",
    "        file.write(' '.join(map(str,spearman[i])))\n",
    "        file.write('\\n')\n",
    "        file.write(f'Kendall coefficients: ')\n",
    "        file.write(' '.join(map(str,kendall[i])))\n",
    "        file.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fourmotors=df[df['metric'].isin(['S117','S118','S169','S170'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel=df[df['metric'] == 'S7'].compute()\n",
    "#sel= sel[sel['hwid'] == 'SW-088']\n",
    "#sel[sel['value']!=0].compute().head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel['value'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>when</th>\n",
       "      <th>hwid</th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1601510485159</td>\n",
       "      <td>SW-065</td>\n",
       "      <td>S40</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>1601510515180</td>\n",
       "      <td>SW-065</td>\n",
       "      <td>S40</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>1601510545278</td>\n",
       "      <td>SW-065</td>\n",
       "      <td>S40</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>1601510575516</td>\n",
       "      <td>SW-065</td>\n",
       "      <td>S40</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>1601510607617</td>\n",
       "      <td>SW-065</td>\n",
       "      <td>S40</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              when    hwid metric  value\n",
       "57   1601510485159  SW-065    S40    133\n",
       "143  1601510515180  SW-065    S40    134\n",
       "283  1601510545278  SW-065    S40    134\n",
       "469  1601510575516  SW-065    S40    135\n",
       "582  1601510607617  SW-065    S40    135"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>when</th>\n",
       "      <th>hwid</th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>424030</th>\n",
       "      <td>1601510458920</td>\n",
       "      <td>SW-088</td>\n",
       "      <td>S7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424168</th>\n",
       "      <td>1601510487842</td>\n",
       "      <td>SW-088</td>\n",
       "      <td>S7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424301</th>\n",
       "      <td>1601510519381</td>\n",
       "      <td>SW-088</td>\n",
       "      <td>S7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424436</th>\n",
       "      <td>1601510548722</td>\n",
       "      <td>SW-088</td>\n",
       "      <td>S7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424619</th>\n",
       "      <td>1601510579582</td>\n",
       "      <td>SW-088</td>\n",
       "      <td>S7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 when    hwid metric  value\n",
       "424030  1601510458920  SW-088     S7      1\n",
       "424168  1601510487842  SW-088     S7      1\n",
       "424301  1601510519381  SW-088     S7      1\n",
       "424436  1601510548722  SW-088     S7      1\n",
       "424619  1601510579582  SW-088     S7      1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sel = sel[sel['value'] != 2]\n",
    "sel[sel['value'] != 0].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([133, 134, 135, 136, 137, 138, 130, 128, 126, 124, 122, 121, 119,\n",
       "       118, 117, 116, 115, 114, 113, 127, 131, 132, 123, 112, 111, 110,\n",
       "       125, 109, 129, 120, 139, 108, 107, 106, 142, 144, 145, 146, 147,\n",
       "       148, 149, 140, 141, 143, 105, 104, 151, 150, 103, 102, 101, 100,\n",
       "       152,   0,  99,  98,  97,  96,  83,  82,  78,  91,  89,  84,  80,\n",
       "        77,  73,  71,  70,  67,  69,  63,  62,  61,  60,  59,  55,  54,\n",
       "        68,  86,  87,  88,  81,  85,  75,  66,  65,  58,  49,  79,  90,\n",
       "        92,  93,  94,  95, 153, 157, 154, 155, 158, 159, 160, 161, 162,\n",
       "       163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
       "       176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 187, 188, 189,\n",
       "       190, 191, 192, 193, 194, 195, 197, 199, 196, 200, 202, 203, 205,\n",
       "       207, 209, 212, 214, 216, 218, 220, 222, 225,  64,  76,  72,  74,\n",
       "        57,  56,  53,  52,  51,  50,  48,  47,  46,  44,  45, 310, 312,\n",
       "       307, 304, 315, 317, 320, 322, 325, 327, 330, 333, 335, 341, 338,\n",
       "       339, 343, 346, 349, 351, 354, 357, 360, 363, 365, 374, 368, 356,\n",
       "       353, 350, 358, 361, 347, 342, 345, 364, 367, 326, 329, 324, 321,\n",
       "       318, 303, 311, 316, 313, 308, 306, 301, 298, 296, 293, 291, 288,\n",
       "       286, 284, 281, 279, 276, 274, 297, 292, 280, 290, 295, 299, 302,\n",
       "       285, 287, 278, 275, 331, 334, 337, 282, 371, 372, 370, 380, 382,\n",
       "       375, 384, 378, 377, 381, 387, 390, 385, 388, 391, 227, 229, 231,\n",
       "       234, 236, 238, 240, 243, 254, 259, 261, 263, 266, 268, 270, 273,\n",
       "       393, 394, 397, 400, 403, 406, 409, 413, 272, 269, 267, 265, 262,\n",
       "       260, 258, 255, 253, 251, 248, 246, 244, 242, 239, 237, 235, 232,\n",
       "       230, 228, 226, 224, 221, 213, 210, 215, 217, 219, 208, 206, 204,\n",
       "       256, 252, 250, 247, 245, 416, 419, 422, 425, 428, 432, 435, 438,\n",
       "       441, 445, 448, 458, 455, 451, 471, 467, 453, 450, 460, 464, 457,\n",
       "       446, 443, 440, 437, 433, 430, 427, 424, 420, 417, 414, 462, 465,\n",
       "       469, 472, 476, 474, 411, 408, 405, 402, 399, 396, 201])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel['value'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
